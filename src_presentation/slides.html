<!DOCTYPE html>
<html>
  <head>
    <title>FaceForensics++: Learning to Detect Facial Images</title>
    <meta charset="utf-8">
    <style>
      /* @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic); */
      @import url(css/uca_metropolis.css);
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle, title-slide
count: false

## <b>FaceForensics++: Learning to Detect Manipulated Facial Images</b><br/><sub>A 2019 paper by A. R√∂ssler et al. (arXiv:1901.08971)</sub>
### Presented by Q. Le Roux (github@qlero)
<br/>
.less-line-height[
.grey[Universit√© C√¥te d'Azur]
]

---

# A Rising Concern

```
        facial expression manipulation
        + facial identity manipulation
          + ubiquitous neural networks
       -------------------------------
       significant concern for society
       (political, economic, societal)
```

<center><img src="images/putin.gif" width="45%" /></center>

.font50[
**Source**: `Kim, H. et al. Deep video portraits. ACM Trans. Graph. (TOG) 2018`
]

---

class: center, middle, title-slide

## Developing detection techniques has become cornerstone of the field of computer vision in recent years.

---

# The Paper's Motivation

<br/>
> To test the realism of state-of-the-art image manipulation

> To standardize the evaluation of detection methods

---

class: center, middle, title-slide

# üßÆ Techniques & State-of-the-Art

---

# Advances in Facial Digitization

<br/>
New techniques, better computers enable facial digitization in two different approaches:

- **Graphics-based**: Relies on expert-selected features and patterns
- **Learning-based**: Relies on neural networks

---

# An Overall Generic Process

<small>The two approaches usually follow the same process:

1. Identify the face region, isolate it
2. Modify the region and recombine

This process usually leaves artifacts, which detection systems might look for.</small>

<center><img src="images/process.png" width=100%/></center>

---

# Expression Manipulation

<small>

State-of-the-art in early 2019:
- Graphics appr.: **NeuralTextures**, `Thies et al., 2019`
- Learning appr.: **Face2Face**, `Thies et al., 2016`

</small>

<center><img src="images/synthesizing_obama.gif" width = "70%"/></center>
<br/>
.font50[
**Sources**: `Thies, J. et al. Face2Face: Real-Time Face Capture & Reenactment. IEEE. 2016; Thies, J. et al. Deffered Neural Rendering. ACM Trans. Graph. (TOG) 2019`
]

---

# Identity Manipulation

<small>

State-of-the-art in early 2019:

- Graphics appr.: **FaceSwap**, `Kowalski, 2016`
- Learning appr.: **DeepFakes**, `deepfakes, 2017`

</small>

<center><img src="images/deepfake.gif" width = "40%"/></center>
<br/><br/>
.font50[
**Sources**: `Kowalski, FaceSwap. GitHub. 2015; Deepfakes Gr., deepfakes. GitHub. 2016` 
]

---

class: center, middle, title-slide

# üóÑÔ∏è The Paper's Approach

---

# The Authors' Objectives

<small>Beyond motivations, the authors set out to publish:

1. A large scale dataset to standardize the industry

2. A state-of-the-art forgery detector

3. An automated benchmark with a human baseline

<u>Overarching goal:</u>

**<center>To thoroughly test the state-of-the-art of facial forgeries</center>**

</small>

---

# The FaceForensics++ Dataset

<small><center>An order of magnitude larger than previous ones.</center>

| Source | <div style="width:200px"># of videos</div> | <div style="width:200px">Compression</div> |
| ----------------: | ----: | ----------: | 
| Original YouTube + actors | 1,000 + 360 | raw, HQ, LQ |
| DeepFakes                 | 1,000 | raw, HQ, LQ |
| Face2Face                 | 1,000 | raw, HQ, LQ |
| FaceSwap                  | 1,000 | raw, HQ, LQ |
| NeuralTextures            | 1,000 | raw, HQ, LQ |

</small>
<br/>
.font50[
**Note**: The dataset amounts to c. 1.8m images. HQ and LQ corresponds to levels of "constant rate quantization" compression, resp. 23 and 40.
]

---

# The FaceForensics++ Dataset

.font70[
Since the inception of the paper, the dataset was updated twice to include:

| Source | <div style="width:180px"># of videos</div> | <div style="width:170px">Compression</div> | <div style="width:150px">Added Date</div> |
| ----------------: | ----: | ----------: | ---: |
| DeepFakeDetection | 3,000 | raw, HQ, LQ | late 2019 |
| FaceShifter       | 1,000 | raw, HQ, LQ | 2020 |
]
<br/><br/>
.font50[
**Sources**: `Dufour et al. Deep Fake Detection Dataset. Google AI. 2019; Li et al. FaceShifter: Towards High Fidelity And Occlusion Aware Face Swapping. CVPR. 2020`
]

---

# Problem Statement To Evaluate FF++

.font70[**Human observer baseline**:
- 50:50 split between pristine and fake images
- 60 images per observer with an viewing time limit up to 6 seconds

**Problem statement for automated solution**: 
- 720/140/140 video split for training, val. and test.
- per-frame binary classification, videos converted to images s.t.:
]

<center><img src="images/split.png" width=90%/></center>

---

# Xception, the then-best detector

<small>

Introduced in 2017, Xception stands for "Extreme-Inception". It is a set of deep and parallel (*depthwise separable*) CNN classifier.

</small>

<center><img src="images/xception.jpg" width = "100%"/></center>

.font50[
**Source**: `Chollet F., Xception: DL with Depthwise Separable Convolutions. CVPR. 2017;Kaggle Leaf Disease challenge; Ma√´l F., Xception Model, Github`
]

---

# The FaceForensics++ Benchmark

.font70[
The benchmark corresponds to **1,000 images** with unknown labels:
- **single frame** from an **unknown video** 
- Manipulated with **DeepFakes**, **Face2Face**, **FaceSwap**, or **NeuralTextures** 
- With random **re-sizing** and **compression**

The automated benchmark is a **website** allowing one submission (e.g. **.JSON file of label predictions**) submission **every 2 weeks**.
]

<center><img src="images/benchpics.jpg" width = "80%"/></center>

---

class: center, middle, title-slide

# üß± Performance & Limitations

---

# Paper results

<center>.font70[
The lower the video quality, the lower the performance.
<center><img src="images/results.png" width = "65%"/></center>
]</center>

---

# Current Benchmark Leaderboard

.font80[Key points:
- The benchmark was not updated with the new data.
- Performances have greatly increased in a few years.
]

<center><img src="images/benchmark.png" width = "100%"/></center>

---

class: center, middle, title-slide

# üåê Future Directions

---

# A Bit of Fun

<center><video width="720" height="480" controls="controls">
<source src="videos/notMorganCrossfade.mp4" type="video/mp4">
</video></center>

.font50[
**Source**: `de Jong, B., Schouwink, B., Deepfake Singularity. 2021.` <small>([link](https://www.youtube.com/watch?v=F4G6GNFz0O8))</small>
]

---

class: center, middle, title-slide

# ü§© It's been a pleasure

## Ask me questions!

    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
